{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSdzzrWrgAXu"
      },
      "source": [
        "# **AP157 Machine Learning Lab Assignment**\n",
        "## Module A1: Regression -- Overfitting, Underfitting, and Cross-Validation\n",
        "\n",
        "_Instructions_: Answer each part of the assignment as completely as you can. Discuss **all** your code and results as clearly and concisely as possible.\n",
        "\n",
        "_Scoring Criteria_: 50% - *correctness of code*; 50% - *discussion of the code and results*. Maximum score is **100 points** (Parts 1 and 2 are worth 20 and 80 points, respectively).\n",
        "\n",
        "_Credits_: This assignment is based on Chapter 8.11 of “Statistics, Data Mining, and Machine Learning in Astronomy” (SDMMLA) by Zeljko Ivezic et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_dmUyo2pxIt"
      },
      "source": [
        "### Student Information\n",
        "\n",
        "_Full Name (Last Name, First Name)_: Clemente, Lance\\\n",
        "_Student No._: 2021-07811\\\n",
        "_Section_: THY-TX-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyO1CnkFp17G"
      },
      "source": [
        "### Submission Information\n",
        "\n",
        "_Date and Time Submitted (most recent upload)_:\n",
        "\n",
        "**HONOR PLEDGE** I affirm that I have upheld the highest principles of honesty and integrity in my academic work and that this lab assignment is my own work.\n",
        "\n",
        "**Sign here with your full name: Lance Veyonce C. Clemente**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgse8Mt5p35S"
      },
      "source": [
        "### Grading Information (c/o Instructor)\n",
        "\n",
        "TOTAL SCORE: **[]**/100\n",
        "\n",
        "Score breakdown:\n",
        "* Part 1 - []/20\n",
        "* Part 2 - []/80\n",
        "\n",
        "_Date and Time Scored (MM/DD/YYYY HH:MM AM/PM):_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAJ7b7cMp6FY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAgom2vqp-2X"
      },
      "source": [
        "#### PART 1 - Generate data set *(20 points)*\n",
        "\n",
        "1. Generate a toy data set with 100 regularly-spaced points and as described by Eq. 8.75-- a simple model where $x$ and $y$ satisfy the following:\n",
        "$$ 0 \\le x_i \\le 3 $$\n",
        "$$ y_i = x_i \\sin(x_i) + \\epsilon_i $$\n",
        "where the noise is drawn from a normal distribution $\\epsilon_i \\sim \\rm{N}(0, 0.1)$. *(10 points)*  \n",
        "\n",
        "2. Plot your toy data set (Refer to Fig. 8.12 for comparison). *(10 points)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbKhGKmgsPCV"
      },
      "source": [
        "PART 2 - Apply cross-validation *(80 points)*\n",
        "\n",
        "Recreate the top panel of Figure 8.14: rms error vs. polynomial degree for the training set and cross-validation set. To do this, you will perform the ff. steps:\n",
        "\n",
        "1. Split the data set into training, cross-validation, and test sets with 50%, 25% and 25% ratio. You can use sklearn library's model_selection.train_test_split function [(link)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). *(20 pts.)*\n",
        "2. Get the best-fit curve for polynomial degrees $d=0$ to 14 for the training set. You can use numpy library's polyfit function [(link)](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html). *(30 pts.)*\n",
        "3. Get the rms errors for both the training and cross-validation sets (for the best-fit curve from Step 2). *(10 pts.)*\n",
        "4. Plot rms errors for both the training and cross-validation sets against polynomial degree $d$ (as in Fig. 8.14). *(20 pts.)*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5i4dEws_ycC"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(0,3,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8_C0CpvqlkI",
        "outputId": "e84d05c2-5f67-4cfe-98a3-e86ca91b9c28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.03030303, 0.06060606, 0.09090909, 0.12121212,\n",
              "       0.15151515, 0.18181818, 0.21212121, 0.24242424, 0.27272727,\n",
              "       0.3030303 , 0.33333333, 0.36363636, 0.39393939, 0.42424242,\n",
              "       0.45454545, 0.48484848, 0.51515152, 0.54545455, 0.57575758,\n",
              "       0.60606061, 0.63636364, 0.66666667, 0.6969697 , 0.72727273,\n",
              "       0.75757576, 0.78787879, 0.81818182, 0.84848485, 0.87878788,\n",
              "       0.90909091, 0.93939394, 0.96969697, 1.        , 1.03030303,\n",
              "       1.06060606, 1.09090909, 1.12121212, 1.15151515, 1.18181818,\n",
              "       1.21212121, 1.24242424, 1.27272727, 1.3030303 , 1.33333333,\n",
              "       1.36363636, 1.39393939, 1.42424242, 1.45454545, 1.48484848,\n",
              "       1.51515152, 1.54545455, 1.57575758, 1.60606061, 1.63636364,\n",
              "       1.66666667, 1.6969697 , 1.72727273, 1.75757576, 1.78787879,\n",
              "       1.81818182, 1.84848485, 1.87878788, 1.90909091, 1.93939394,\n",
              "       1.96969697, 2.        , 2.03030303, 2.06060606, 2.09090909,\n",
              "       2.12121212, 2.15151515, 2.18181818, 2.21212121, 2.24242424,\n",
              "       2.27272727, 2.3030303 , 2.33333333, 2.36363636, 2.39393939,\n",
              "       2.42424242, 2.45454545, 2.48484848, 2.51515152, 2.54545455,\n",
              "       2.57575758, 2.60606061, 2.63636364, 2.66666667, 2.6969697 ,\n",
              "       2.72727273, 2.75757576, 2.78787879, 2.81818182, 2.84848485,\n",
              "       2.87878788, 2.90909091, 2.93939394, 2.96969697, 3.        ])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.append(x, np.linspace(0,3,100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh4nhi94-tXb"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot((np.sin(x)*x))\n",
        "##PART 1, (np.sin(x)*x)+np.random.normal(0,0.1,100) is the main data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_PfXVXEH7JN"
      },
      "outputs": [],
      "source": [
        "y = (np.sin(x)*x)+np.random.normal(0,0.1,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLMzHdYmL5hB"
      },
      "outputs": [],
      "source": [
        "x_train, x_training, y_train, y_training = train_test_split(x, y, test_size=0.50)\n",
        "x_train2, x_cross, y_train2, y_cross = train_test_split(x_training, y_training, test_size=0.50)\n",
        "x_train3, x_test, y_train3, y_test = train_test_split(x_cross, y_cross, test_size=0.50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9i1WtR7RBxK"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, y_train, color = 'blue')\n",
        "plt.scatter(x_test, y_test, color = 'red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvcdcousXQvn"
      },
      "outputs": [],
      "source": [
        "numpy.polyfit(x_train, y, deg, rcond=None, full=False, w=None, cov=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhuFJ65jPafC"
      },
      "outputs": [],
      "source": [
        "max_BA_per_Z = []  # List to store maximum BA values for each Z\n",
        "\n",
        "for Z in range(0, 14):\n",
        "    max_BA = -float('inf')  # Initialize max_BA to negative infinity for each Z\n",
        "    best_A_for_Z = None  # Initialize best_A_for_Z as None\n",
        "\n",
        "    for A in range(Z, 3 * Z + 1):\n",
        "        if int(A) % 2 == 0 and int(Z % 2 == 1):\n",
        "            a5 = -12.0\n",
        "        elif int(A) % 2 == 0 and int(Z) % 2 == 0:\n",
        "            a5 = 12.0\n",
        "        else:\n",
        "            a5 = 0\n",
        "\n",
        "        B = (a1 * A) - (a2 * pow(A, 2/3)) - (a3 * pow(Z, 2) / pow(A, 1/3)) - (a4 * pow(A - (2 * Z), 2) / A) - (a5 / pow(A, 1/2))\n",
        "        BA = B / A\n",
        "\n",
        "        # Check if the current BA is the highest for this Z\n",
        "        if BA > max_BA:\n",
        "            max_BA = BA\n",
        "            best_A_for_Z = A\n",
        "\n",
        "    max_BA_per_Z.append((Z, best_A_for_Z, max_BA))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}